{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a748b392-3481-4d20-8a37-40dc0f17bad3",
   "metadata": {},
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85811d22-d8d0-483d-abcd-5a1c292e9b30",
   "metadata": {},
   "source": [
    "Missing values in a dataset refer to the absence of values for one or more features in some or all observations.It is essential to handle missing values in a dataset because they can lead to biased or inaccurate results when analyzing the data or building models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce339ec-f1ab-42ad-9a45-58066d57610d",
   "metadata": {},
   "source": [
    "1.Decision trees: Decision trees can handle missing values in features by creating additional branches in the tree to handle the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb746e-5b7f-46ef-ac3f-4aebbd4f950d",
   "metadata": {},
   "source": [
    "2.Random forests: Random forests can handle missing values in features by using the mode of the available values to split the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b781ca76-6570-47a5-ac6e-51a684ec9182",
   "metadata": {},
   "source": [
    "3.Support Vector Machines (SVMs): SVMs can handle missing values by ignoring the missing values and only using the available features to find the optimal hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42543cc-ea63-4995-9a37-475426d08452",
   "metadata": {},
   "source": [
    "4.K-Nearest Neighbors (KNN): KNN can handle missing values by ignoring the missing values and only using the available features to find the k-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae90c71-4ba9-4357-9333-ea50239ca492",
   "metadata": {},
   "source": [
    "5.K-Nearest Neighbors (KNN): KNN can handle missing values by ignoring the missing values and only using the available features to find the k-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcae5ff-9306-4567-8f8a-cd4ae0e47d82",
   "metadata": {},
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622e00a7-bb86-4f33-92e6-960e4b507655",
   "metadata": {},
   "source": [
    "1.Deletion methods: This involves removing observations or features with missing values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91907867-68c7-40fd-9562-587b2a7afe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A     B\n",
      "0  1.0   6.0\n",
      "2  3.0   8.0\n",
      "3  NaN   9.0\n",
      "4  5.0  10.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe with missing data\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, None, 5],\n",
    "    'B': [6, None, 8, 9, 10]\n",
    "})\n",
    "\n",
    "# use pairwise deletion to remove missing data in the 'B' column\n",
    "df.dropna(subset=['B'], inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018e951-ccc3-48e3-a5e6-a1475006fe82",
   "metadata": {},
   "source": [
    "2.Imputation methods: This involves filling in the missing values with estimated values. There are several techniques for imputing missing values, including mean imputation, median imputation, mode imputation, and regression imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df872209-d16b-4c87-8dd2-2b506e0f284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Create an imputer object with mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Impute missing values in the dataset\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# View the cleaned dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd0f242-e164-45c8-aaa7-dacf1de6c807",
   "metadata": {},
   "source": [
    "3.Prediction methods: This involves using machine learning models to predict the missing values based on the relationships between the available features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf700d8-3022-4266-8220-10525855bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Create an imputer object with KNN strategy\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Impute missing values in the dataset\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# View the cleaned dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864a17f-0f04-42de-8b8b-e6d26d1e43cc",
   "metadata": {},
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20801ba9-2d15-479b-93ed-3674aab8c6ee",
   "metadata": {},
   "source": [
    "Imbalanced data refers to a situation where one target class represents a significant portion of observations. Imbalanced datasets can cause problems in both model training and evaluation because model training and evaluation are commonly run with the assumption that there are an adequate number of observations for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d16cd-d458-4c75-9543-d7992e3e4ed1",
   "metadata": {},
   "source": [
    "If imbalanced data is not handled, it can lead to poor performance of machine learning models. For example, if we have a dataset in which 92% of the data is labelled as ‘Not Fraud’ and the remaining 8% are cases of ‘Fraud’, then accuracy can be misleading. In such cases, we need to use techniques like undersampling, oversampling, SMOTE etc., to handle imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e383ab-a8f1-40b6-a4de-e534b7927d1c",
   "metadata": {},
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec1512-74fb-49dc-b1b1-970a60abb626",
   "metadata": {},
   "source": [
    "Up-sampling involves randomly duplicating observations from the minority class, whereas down-sampling involves randomly removing observations from the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7525697-07f8-44b1-b883-4e50e06c6ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_1  feature_2  target\n",
      "0          1          1       0\n",
      "1          2          0       0\n",
      "2          3          1       0\n",
      "3          4          0       0\n",
      "4          5          1       0\n",
      "7          8          0       1\n",
      "9         10          0       1\n",
      "7          8          0       1\n",
      "6          7          1       1\n",
      "8          9          1       1\n",
      "   feature_1  feature_2  target\n",
      "5          6          0       1\n",
      "6          7          1       1\n",
      "7          8          0       1\n",
      "8          9          1       1\n",
      "9         10          0       1\n",
      "1          2          0       0\n",
      "3          4          0       0\n",
      "4          5          1       0\n",
      "0          1          1       0\n",
      "2          3          1       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# create a sample imbalanced dataset\n",
    "data = {'feature_1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'feature_2': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n",
    "        'target': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# separate majority and minority classes\n",
    "majority_class = df[df.target==0]\n",
    "minority_class = df[df.target==1]\n",
    "\n",
    "# up-sample minority class\n",
    "minority_upsampled = resample(minority_class, replace=True, n_samples=len(majority_class), random_state=123)\n",
    "\n",
    "# down-sample majority class\n",
    "majority_downsampled = resample(majority_class, replace=False, n_samples=len(minority_class), random_state=123)\n",
    "\n",
    "# combine majority and minority classes\n",
    "upsampled_df = pd.concat([majority_class, minority_upsampled])\n",
    "downsampled_df = pd.concat([minority_class, majority_downsampled])\n",
    "\n",
    "print(upsampled_df)\n",
    "print(downsampled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9463f97b-695b-4ccb-ace0-7a4a3a7c7649",
   "metadata": {},
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfbff23-45cb-44af-9b63-133a218c5191",
   "metadata": {},
   "source": [
    "Data augmentation is a technique used in machine learning and computer vision to artificially increase the size of a training dataset by creating new training samples from existing ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d9ae38-37b0-4427-b236-9b079fc9ae0c",
   "metadata": {},
   "source": [
    "SMOTE (Synthetic Minority Over-sampling Technique) is an algorithm that performs data augmentation by creating synthetic data points based on the original data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264a96f1-1034-42f1-a703-e2043b212021",
   "metadata": {},
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3938cc-ca19-4da5-82f0-aa24b4e811fc",
   "metadata": {},
   "source": [
    "Outliers are data points that are significantly different from other data points in a dataset. They can be caused by measurement errors, data entry errors, or natural variation in the population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94059bd-7e00-4904-940e-8a7cd0260ef5",
   "metadata": {},
   "source": [
    "It is essential to handle outliers because they can have a significant impact on statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a897c19f-ea04-44f1-9257-f17f7af47f66",
   "metadata": {},
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444a9c67-bd75-404a-af5e-ec58ec72393a",
   "metadata": {},
   "source": [
    "1.Mean / median imputation: In this technique, missing values are replaced with the mean or median value of the respective variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc87ccac-fb74-447e-8b08-e9bcc5cd32f7",
   "metadata": {},
   "source": [
    "2.Mode imputation: This technique is used when the data is categorical. The missing values are replaced with the most frequent value of the respective variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02e0ac-8362-45c9-8c96-b5c2e0406f03",
   "metadata": {},
   "source": [
    "3.Backward/forward filling: This technique is useful when the missing data is in a time series dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b48c3-d643-460f-8667-a9be06554b8c",
   "metadata": {},
   "source": [
    "4.Hot-deck imputation: In this technique, missing values are replaced with values from similar cases or observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4616699-a6c3-415d-9d68-9408d6b192c3",
   "metadata": {},
   "source": [
    "5.Regression imputation: This technique involves using regression analysis to predict the missing values based on the relationship between the dependent and independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3844088e-0651-4cbe-87cd-c93af3d39a18",
   "metadata": {},
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace6c64b-731e-48e0-8f5b-3c2be94046a2",
   "metadata": {},
   "source": [
    "1.Visual inspection: One way to identify patterns in missing data is to visually inspect the dataset using plots, such as scatter plots or histograms, to see if there is a relationship between the missing data and other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5941e2-28a8-4724-b63e-7644a918e08d",
   "metadata": {},
   "source": [
    "2.Missing data analysis: You can perform a missing data analysis to examine the patterns in the missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d721501-f9d1-4229-b10e-e5593e454f28",
   "metadata": {},
   "source": [
    "3.Statistical tests: You can use statistical tests, such as the Little's MCAR (Missing Completely At Random) test or the MNAR (Missing Not At Random) test, to determine if the missing data is missing at random or if there is a pattern to the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0150f94-7c60-4c5f-b4b1-189f24f36155",
   "metadata": {},
   "source": [
    "4.Imputation and analysis: Another strategy is to impute the missing data using various techniques, such as mean/median imputation or regression imputation, and analyze the impact of the imputation on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0217a7-3112-421e-8aa1-64b1b9086774",
   "metadata": {},
   "source": [
    "5.Expert knowledge: Finally, you can consult with domain experts to determine if there are any known reasons or patterns for the missing data, such as missing data due to measurement error or non-response bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be700b-20b0-4d54-ac48-f93c64d94cc4",
   "metadata": {},
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5b8c7e-eddc-49c6-b4ed-e523d0a4ab56",
   "metadata": {},
   "source": [
    "1.Confusion matrix: The confusion matrix is a table that shows the number of true positives, true negatives, false positives, and false negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a9de8-4658-451d-af6f-23bd0159755f",
   "metadata": {},
   "source": [
    "2.Accuracy metrics: Accuracy metrics such as precision, recall, F1 score, and ROC-AUC can be used to evaluate the model's performance on an imbalanced dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368ccd2-73c8-4898-af60-c941c6794c9a",
   "metadata": {},
   "source": [
    "3.Resampling techniques: Resampling techniques such as oversampling and undersampling can be used to balance the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5bebbc-a7ce-496d-b097-da631ecee43f",
   "metadata": {},
   "source": [
    "4.Cost-sensitive learning: Cost-sensitive learning is a technique that assigns different weights to different classes based on their importance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d2aaed-d407-451e-9d84-c6aec16fc5a2",
   "metadata": {},
   "source": [
    "5.Ensemble models: Ensemble models such as bagging, boosting, and stacking can be used to improve the performance of the model on an imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a6c34-68f5-4fc2-8f72-3c7e491f5ee6",
   "metadata": {},
   "source": [
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e6c1ea-b51d-4c63-9124-0563c24703c0",
   "metadata": {},
   "source": [
    "1.Random under-sampling: This method involves randomly removing some of the majority class samples until the dataset is balanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ddf26e-a03a-4e08-8e8b-71bec07ec9ce",
   "metadata": {},
   "source": [
    "2.Cluster-based under-sampling: This method involves identifying clusters of samples from the majority class and keeping only the centroid of each cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cecf6c-29a5-4278-b2b2-9079030bd5a0",
   "metadata": {},
   "source": [
    "3.Tomek links: Tomek links are pairs of samples from different classes that are very close to each other. By removing the majority class sample from a Tomek link, we can create a smaller and more balanced dataset while keeping the most informative samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e0e853-91be-4116-85d8-3d7d6a937169",
   "metadata": {},
   "source": [
    "4.Edited nearest neighbors: This method involves identifying the samples in the majority class that are misclassified by the nearest neighbor classifier and removing them from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171040f-c66c-4a00-82a7-fb31b4adea1d",
   "metadata": {},
   "source": [
    "5.Synthetic minority oversampling technique (SMOTE): SMOTE is a method that generates synthetic samples for the minority class by creating new samples between existing samples of the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd44231-6c3c-47b5-b78b-fd3252e83faf",
   "metadata": {},
   "source": [
    "Once you have down-sampled the majority class, you can train a model on the balanced dataset to estimate customer satisfaction. It's important to note that down-sampling the majority class may result in a smaller dataset and may lead to a loss of information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f3b52e-7f45-40e6-a265-2aa09048a2c2",
   "metadata": {},
   "source": [
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc66c3-286b-4357-935b-7974ba4cb0f7",
   "metadata": {},
   "source": [
    "1.Random over-sampling: This method involves randomly replicating some of the minority class samples until the dataset is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04fa0c-e22f-4cbd-b890-e537f1fca9c1",
   "metadata": {},
   "source": [
    "2.Synthetic minority oversampling technique (SMOTE): SMOTE is a method that generates synthetic samples for the minority class by creating new samples between existing samples of the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02073e04-c9a5-41a9-ba52-533ff7be8677",
   "metadata": {},
   "source": [
    "3.Adaptive synthetic sampling (ADASYN): ADASYN is a method that generates synthetic samples for the minority class based on the density distribution of the minority class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4364331-c55a-4363-b7b8-8d9275f99f4c",
   "metadata": {},
   "source": [
    "4.Cluster-based over-sampling: This method involves identifying clusters of samples from the minority class and replicating them to increase their representation in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f35d08-9ed3-4d8a-b6a0-551feb50e8b8",
   "metadata": {},
   "source": [
    "5.Kernel Density Estimation (KDE) based over-sampling: This method involves estimating the density distribution of the minority class and creating new samples based on the estimated distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
